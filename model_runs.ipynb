{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import get_adasyn_data, get_smote_data, get_ros_data\n",
    "from model_utils import model_pipeline, run_all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [RandomForestClassifier(n_jobs=-1, random_state=123, max_depth=16, max_features='sqrt', n_estimators=110),\n",
    "         DecisionTreeClassifier(random_state=123, criterion='entropy', max_depth=2), \n",
    "         LogisticRegression(n_jobs=-1,max_iter=2000, random_state=123, C=0.1, solver='newton-cg'), \n",
    "         KNeighborsClassifier(n_jobs=-1, leaf_size=1, n_neighbors=5, p=2),\n",
    "         MLPClassifier(random_state=123, activation='relu', alpha=0.0001, hidden_layer_sizes=(20,), learning_rate='constant', solver='adam', max_iter=5000), \n",
    "         GaussianNB(var_smoothing=1e-09), \n",
    "         SVC(random_state=123, C=0.1, kernel='rbf')]\n",
    "# rf_params = {'max_depth': 16, 'max_features': 'sqrt', 'n_estimators': 110}\n",
    "# dt_params = {'criterion': 'entropy', 'max_depth': 2}\n",
    "# lr_params = {'C': 0.1, 'solver': 'newton-cg'}\n",
    "# knn_params = {'leaf_size':range(1,50), 'n_neighbors':range(1,30), 'p':[1,2]}\n",
    "# mlp_params = {\n",
    "#     'activation': ['tanh', 'relu'],\n",
    "#     'solver': ['sgd', 'adam'],\n",
    "#     'alpha': [0.0001, 0.05],\n",
    "#     'learning_rate': ['constant','adaptive'],\n",
    "# }\n",
    "# params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "# svc_params = {'C': [0.1, 1, 10, 100, 1000], \n",
    "#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "#               'kernel': ['rbf']} \n",
    "params = [None, None, None, None, None, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_data = get_smote_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn_data = get_adasyn_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_results, reports \u001b[39m=\u001b[39m run_all_models(models, smote_data, \u001b[39m'\u001b[39m\u001b[39m_smote\u001b[39m\u001b[39m'\u001b[39m, params)\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39moutput_smote1.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     f\u001b[39m.\u001b[39mwrite(cap\u001b[39m.\u001b[39mstdout)\n\u001b[1;32m      4\u001b[0m \u001b[39mdel\u001b[39;00m cap\n\u001b[1;32m      5\u001b[0m cap\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "model_results, reports = run_all_models(models, smote_data, '_smote', params)\n",
    "with open('output_smote1.txt', 'w') as f:\n",
    "    f.write(cap.stdout)\n",
    "del cap\n",
    "# cap.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [RandomForestClassifier(n_jobs=-1, random_state=123, max_depth=16, max_features='sqrt', n_estimators=160),\n",
    "         DecisionTreeClassifier(random_state=123, criterion='entropy', max_depth=2), \n",
    "         LogisticRegression(n_jobs=-1,max_iter=2000, random_state=123, C=0.1, solver='newton-cg'), \n",
    "         KNeighborsClassifier(n_jobs=-1, leaf_size=1, n_neighbors=3, p=1),\n",
    "         MLPClassifier(random_state=123, activation='tanh', alpha=0.0001, hidden_layer_sizes=(20,), learning_rate='constant', solver='adam', max_iter=5000), \n",
    "         GaussianNB(var_smoothing=1.873817422860387e-09), \n",
    "         SVC(random_state=123, C=0.1, kernel='rbf')]\n",
    "# rf_params = {'max_depth': [16], 'max_features': ['sqrt'], 'n_estimators': 110}\n",
    "# dt_params = {'criterion': 'entropy', 'max_depth': 2}\n",
    "# knn_params = {'leaf_size':range(1,50), 'n_neighbors':range(1,30), 'p':[1,2]}\n",
    "# mlp_params = {\n",
    "#     'activation': ['tanh', 'relu'],\n",
    "#     'solver': ['sgd', 'adam'],\n",
    "#     'alpha': [0.0001, 0.05],\n",
    "#     'learning_rate': ['constant','adaptive'],\n",
    "# }\n",
    "# params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "# svc_params = {'C': [0.1, 1, 10, 100, 1000], \n",
    "#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "#               'kernel': ['rbf']} \n",
    "params = [None, None, None, None, None, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "run_all_models(models, adasyn_data, '_adasyn', params)\n",
    "with open('output_adasyn1.txt', 'w') as f:\n",
    "    f.write(cap.stdout)\n",
    "# model_results, reports = run_all_models(models, adasyn_data, '_adasyn', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier_adasyn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       947\n",
      "           1       0.94      0.99      0.96       930\n",
      "\n",
      "    accuracy                           0.96      1877\n",
      "   macro avg       0.96      0.96      0.96      1877\n",
      "weighted avg       0.96      0.96      0.96      1877\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "DecisionTreeClassifier_adasyn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.60      0.73       947\n",
      "           1       0.70      0.96      0.81       930\n",
      "\n",
      "    accuracy                           0.78      1877\n",
      "   macro avg       0.82      0.78      0.77      1877\n",
      "weighted avg       0.82      0.78      0.77      1877\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "LogisticRegression_adasyn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       947\n",
      "           1       0.85      0.88      0.87       930\n",
      "\n",
      "    accuracy                           0.87      1877\n",
      "   macro avg       0.87      0.87      0.87      1877\n",
      "weighted avg       0.87      0.87      0.87      1877\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "Best params are:  {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n",
      "GridSearchCV_adasyn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       947\n",
      "           1       0.90      0.99      0.95       930\n",
      "\n",
      "    accuracy                           0.94      1877\n",
      "   macro avg       0.95      0.94      0.94      1877\n",
      "weighted avg       0.95      0.94      0.94      1877\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "Best params are:  {'activation': 'tanh', 'alpha': 0.0001, 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "GridSearchCV_adasyn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       947\n",
      "           1       0.92      0.96      0.94       930\n",
      "\n",
      "    accuracy                           0.94      1877\n",
      "   macro avg       0.94      0.94      0.94      1877\n",
      "weighted avg       0.94      0.94      0.94      1877\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "Best params are:  {'var_smoothing': 1.873817422860387e-09}\n",
      "GridSearchCV_adasyn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.45       947\n",
      "           1       0.58      1.00      0.73       930\n",
      "\n",
      "    accuracy                           0.64      1877\n",
      "   macro avg       0.79      0.65      0.59      1877\n",
      "weighted avg       0.79      0.64      0.59      1877\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "Best params are:  {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "GridSearchCV_adasyn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       947\n",
      "           1       0.50      1.00      0.66       930\n",
      "\n",
      "    accuracy                           0.50      1877\n",
      "   macro avg       0.25      0.50      0.33      1877\n",
      "weighted avg       0.25      0.50      0.33      1877\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cap.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros_data = get_ros_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _, reports \u001b[39m=\u001b[39m run_all_models(models, ros_data, \u001b[39m'\u001b[39m\u001b[39m_ros\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/source/repos/Stroke_prediction/model_utils.py:46\u001b[0m, in \u001b[0;36mrun_all_models\u001b[0;34m(models, data, suffix, params)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(models)):\n\u001b[1;32m     45\u001b[0m     model \u001b[39m=\u001b[39m models[x]\n\u001b[0;32m---> 46\u001b[0m     param \u001b[39m=\u001b[39m params[x]\n\u001b[1;32m     47\u001b[0m     model_result, report \u001b[39m=\u001b[39m model_pipeline(model, data, suffix, param)\n\u001b[1;32m     48\u001b[0m     trained_models\u001b[39m.\u001b[39mappend(model_result)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "_, reports = run_all_models(models, ros_data, '_ros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3713"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adasyn_data[2].count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3721"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_data[2].count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "901"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_data[3].count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbe20b6bb68705ca0eb3658eced2db84947d1d29d55e0b916e191d08ecf3d16a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
